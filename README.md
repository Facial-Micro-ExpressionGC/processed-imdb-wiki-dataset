# Processed IMDB WIKI Dataset

IMDB WIKI dataset is the largest dataset of face images with gender, age and name. It contaiins more that 500K images of human face along with their meta data in a `.mat` file. In this project, I preprocess all the images and meta data and store them in `.csv` files that can be used for any other machine learning or deep learning project very easaly. 

<p align="center">
  <img src="https://user-images.githubusercontent.com/34741145/51108233-75bac680-1817-11e9-8b79-6a1ee05d8aa4.png" />
</p>

## Table of contents:
- [Introduction](#introduction)
- [IMDB WIKI Dataset](#dataset)
- [The Problem](#the)
- [The Solution](#the-solution)
- [File Structure](#file)
- [How to Run Locally](#how)
- [Acknowledgments](#acknowledgments)

## Introduction
Introduction

## IMDB WIKI Dataset
imdb

## The Problem
problem

## The Solution
solution

## File Structure
files

## How to Run Locally
locally

## Acknowledgments
Acknowledgments
